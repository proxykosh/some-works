{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Задача с кагла.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOOEExjRmLXHIUGv+DyPZp+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/proxykosh/some-works/blob/main/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D1%81_%D0%BA%D0%B0%D0%B3%D0%BB%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Цель задачи было определить, будет ли пользователь выплачивать кредит по его предыдущим транзакциям. ***\n",
        "\n",
        "**Оригинал текста задания:**"
      ],
      "metadata": {
        "id": "7U7ciV8POtDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The objective of this competition is to predict the probability that a customer does not pay back their credit card balance amount in the future based on their monthly customer profile. The target binary variable is calculated by observing 18 months performance window after the latest credit card statement, and if the customer does not pay due amount in 120 days after their latest statement date it is considered a default event.\n",
        "\n",
        "The dataset contains aggregated profile features for each customer at each statement date. Features are anonymized and normalized, and fall into the following general categories:\n",
        "\n",
        "D_* = Delinquency variables\n",
        "S_* = Spend variables\n",
        "P_* = Payment variables\n",
        "B_* = Balance variables\n",
        "R_* = Risk variables\n",
        "with the following features being categorical:\n",
        "\n",
        "['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
        "\n",
        "Your task is to predict, for each customer_ID, the probability of a future payment default (target = 1).\n",
        "\n",
        "Note that the negative class has been subsampled for this dataset at 5%, and thus receives a 20x weighting in the scoring metric.\n",
        "\n",
        "\n",
        "\n",
        "Импорт библиотек: "
      ],
      "metadata": {
        "id": "SMYJ5tYWOJtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "        "
      ],
      "metadata": {
        "id": "_KT0NMv-OHjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обработка имеющихся данных.\n",
        "Целью было объединить всю информацию о пользователе в одной строке. Для этого была произведена аггрегация по нескольким показателям. Также для улучшения качества работы модели была произведена стандартизация значений. Для категориальных данных была произведена процедура ван-хот кодирования. "
      ],
      "metadata": {
        "id": "d6OznI7VOHyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = 1_000_000\n",
        "trows = int(rows - rows * 0.8)\n",
        "data = pd.read_csv('../input/amex-default-prediction/train_data.csv', nrows = rows)\n",
        "\n",
        "cat_features = [\n",
        "        \"B_30\",\n",
        "        \"B_38\",\n",
        "        \"D_114\",\n",
        "        \"D_116\",\n",
        "        \"D_117\",\n",
        "        \"D_120\",\n",
        "        \"D_126\",\n",
        "        \"D_63\",\n",
        "        \"D_64\",\n",
        "        \"D_66\",\n",
        "        \"D_68\"]\n",
        "temp_cat_data = pd.DataFrame(data['customer_ID'])\n",
        "\n",
        "for col in cat_features:\n",
        "    temp_cat_data = temp_cat_data.join(pd.DataFrame(pd.get_dummies(data[col])), how='outer', lsuffix = 'l')\n",
        "    \n",
        "    \n",
        "temp_cat_data.columns = [str(i) for i in range(len(temp_cat_data.columns))]\n",
        "temp_cat_data.rename(columns={'0': 'customer_ID'}, inplace=True)\n",
        "temp_cat_data = temp_cat_data.groupby('customer_ID').agg(['sum', 'max', 'min', 'first', 'last', 'std'])\n",
        "temp_cat_data[temp_cat_data.columns[:]] = StandardScaler().fit_transform(temp_cat_data[temp_cat_data.columns[:]].fillna(0))\n",
        "\n",
        "\n",
        "num_cols = []\n",
        "for i in data.columns:\n",
        "    if i not in cat_features:\n",
        "        num_cols.append(i)\n",
        "        \n",
        "num_cols.remove('S_2')\n",
        "num_data = data[num_cols].groupby('customer_ID').agg(['sum', 'max', 'min', 'first', 'last', 'std'])\n",
        "num_data = num_data.reset_index(level=0)\n",
        "num_data[num_data.columns[1:]] = StandardScaler().fit_transform(num_data[num_data.columns[1:]].fillna(0))\n",
        "num_data.columns = [str(i) for i in range(len(num_data.columns))]\n",
        "num_data.rename(columns={'0': 'customer_ID'}, inplace=True)\n",
        "\n",
        "\n",
        "data = num_data.join(temp_cat_data, on = 'customer_ID', how = 'inner')\n"
      ],
      "metadata": {
        "id": "FiX1ebvvOH9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделение на тестовую и учебную выборки\n"
      ],
      "metadata": {
        "id": "bcl01MJNOIFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv', nrows = data.shape[0])['target'].to_numpy().astype(np.int32)\n",
        "data = data[data.columns[1:]].to_numpy().astype(np.float32)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "bolB_geaOINQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как классы имеют разные веса, был использован инструмент для подсчета веса каждого класса. Результата в конкретной задаче это не дало, но использование этого параметра в моделе выглядит полезным для дальнейших задач. "
      ],
      "metadata": {
        "id": "gFkBzDADOIUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        " \n",
        "classes = np.unique(y_train)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weights = dict(zip(classes, weights))"
      ],
      "metadata": {
        "id": "WOXugPqVQCo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализация модели. Я не имел возможности сделать грид серч, так что параметры выбраны интуитивно. "
      ],
      "metadata": {
        "id": "Tg9KNRTbQCx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "best_model = CatBoostClassifier(\n",
        "   bagging_temperature=1,\n",
        "   task_type = 'GPU',\n",
        "   random_strength=1,\n",
        "   thread_count=-1,\n",
        "   class_weights=class_weights, \n",
        "   iterations=30000,\n",
        "   l2_leaf_reg = 4.0, \n",
        "   learning_rate = 0.008,\n",
        "   snapshot_file='snapshot_best.bkp',\n",
        "   random_seed=63,\n",
        "   od_type='Iter',\n",
        "   od_wait=20,\n",
        "   custom_loss=['AUC', 'Accuracy']\n",
        ")\n",
        "\n",
        "best_model.fit(\n",
        "   X_train, y_train  \n",
        ")"
      ],
      "metadata": {
        "id": "byPHhi40QC4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Вывод результатов. Данная обработка давала 95 процентов правильно определенных записей относительно первого класа и 85 процентов второго.\n"
      ],
      "metadata": {
        "id": "L_DffMZZQC9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted =  best_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,predicted))"
      ],
      "metadata": {
        "id": "0xBnRJLbQDCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для проверки качества работы пробовал использовать другую модель градиентного бустинга, но она работа чуть хуже катбуста. "
      ],
      "metadata": {
        "id": "w9IO6lJrQDHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm\n",
        "parameters = {\n",
        "    'application': 'binary',\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc',\n",
        "    'is_unbalance': 'true',\n",
        "    'boosting': 'dart',\n",
        "    'num_leaves': 31,\n",
        "    'feature_fraction': 0.5,\n",
        "    'bagging_fraction': 0.5,\n",
        "    'bagging_freq': 20,\n",
        "    'learning_rate': 0.05,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "train_data = lightgbm.Dataset(X_train, label=y_train)\n",
        "test_data = lightgbm.Dataset(X_test, label=y_test)\n",
        "\n",
        "\n",
        "model = lightgbm.train(parameters,\n",
        "                       train_data,\n",
        "                       valid_sets=test_data,\n",
        "                       num_boost_round=500,\n",
        "                       early_stopping_rounds=100)\n"
      ],
      "metadata": {
        "id": "y4fcs_E1QMBI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}